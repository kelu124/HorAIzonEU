---
layout: default
title: Researchers
parent: Rationale
nav_order: 10
---


1. **Recommendations for Researchers:**
   - Researchers should remain ultimately responsible for the scientific output generated by or with the support of AI tools.
   - Use generative AI transparently by detailing which tools have been used substantially in research processes.
   - Pay attention to privacy, confidentiality, and intellectual property rights when sharing sensitive information with AI tools.
   - Researchers should not use generative AI tools substantially in sensitive activities that could impact others unfairly.

## Responsibility

The guidelines on the responsible use of generative AI in research developed by the European Research Area Forum emphasize that researchers should always maintain ultimate responsibility for the scientific outcomes produced with the assistance of AI tools. This means that researchers are held accountable for the integrity of the content generated by these tools and must be aware of any limitations, such as biases or inaccuracies, that may be present in the AI-generated output. It is crucial that researchers do not rely solely on AI systems for authorship or co-authorship, as the responsibility and agency of authorship should remain with human researchers to ensure the credibility and ethical standards of the research.

Furthermore, the guidelines stress that researchers should refrain from using fabricated material created by generative AI in the scientific process, such as falsifying or manipulating original research data. This is to uphold the principles of research integrity and ensure that the research conducted with AI tools is conducted ethically and transparently. By maintaining a critical approach to the output produced by generative AI, researchers can uphold the standards of scientific research and ensure that the use of AI tools enhances, rather than compromises, the quality and reliability of research outcomes.


## Transparency

Specifically, researchers are encouraged to detail which generative AI tools have been substantially used in their research processes. This means providing clear information about the tools, including their names, versions, dates of use, and how they have impacted the research process. By being transparent about the tools used, researchers can ensure that the research community is aware of the technologies involved and can assess the validity and reliability of the research outcomes.

In line with these guidelines, researchers are urged to openly share the input (prompts) and output of the generative AI tools they have used in their research. This transparency helps to uphold the principles of open science and allows for the reproducibility and robustness of research results. By disclosing the tools used and how they have influenced the research process, researchers contribute to a culture of accountability and integrity in the scientific community, fostering trust and collaboration among peers in the field of generative AI research.


## Privacy

Researchers are advised to be cautious when providing third parties' personal data to online generative AI systems, ensuring that explicit consent is obtained from the data subjects. It is crucial to understand the technical and ethical implications surrounding privacy options, data management, and the implications of sharing information with AI tools, ranging from closed environments to open internet-accessible platforms.

When it comes to recommendations for researchers, the guidelines stress the need to handle sensitive information responsibly and appropriately. Researchers are encouraged to protect unpublished or sensitive work by refraining from uploading it into online AI systems unless assurances are in place to prevent data reuse. By being mindful of privacy, confidentiality, and intellectual property rights, researchers can ensure that the use of generative AI tools aligns with ethical standards and legal requirements, fostering a culture of responsible AI usage in research.


## Unfairness

This means refraining from using AI tools in tasks like peer reviews or evaluations, where the limitations of the technology, such as bias and inaccuracies, could lead to unfair treatment or assessment. By avoiding substantial use of generative AI in sensitive activities, researchers can mitigate the risks associated with the technology's potential limitations, ensuring a fair and ethical research environment.

The European Research Area Forum's guidelines aim to promote a responsible and ethical approach to using generative AI in research. By advising researchers to steer clear of using AI tools substantially in sensitive activities that could impact others unfairly, the guidelines prioritize the integrity and fairness of research practices. This recommendation underscores the importance of considering the potential risks and limitations of generative AI tools in research activities, highlighting the need for researchers to use these technologies judiciously and ethically to uphold the standards of scientific integrity.
